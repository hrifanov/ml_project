{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras.utils import plot_model, image_dataset_from_directory\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import convert_to_tensor\n",
    "import tensorflow.keras.backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = '../../../Dataset/img_celeba_cropped'\n",
    "identity_path = '../../../Dataset/identity_CelebA.txt'\n",
    "attributes_path = '../../../Dataset/list_attr_celeba.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_num = 5000\n",
    "image_shape = (224, 224, 3)\n",
    "\n",
    "batch_size = 10\n",
    "lr=0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeb_identity = pd.read_csv(identity_path, sep = \" \", names=[\"image\", \"identity\"])[:images_num-1]\n",
    "celeb_identity[\"identity\"] = celeb_identity[\"identity\"].astype(\"string\")\n",
    "\n",
    "celeb_attrs = pd.read_csv(attributes_path, sep = \"\\s+\")[:images_num-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_balanced_pair(column:str, pairing_column:str, df=celeb_identity):\n",
    "    # getting random identity from the provided column to use for balanced pair\n",
    "    random_id = df[column].sample(1, replace=True).to_string(index=False)\n",
    "    containing_id_list = df.loc[df[column] == random_id][pairing_column].sample(2, replace=True).to_list()\n",
    "    \n",
    "    # random pictures for pair generation\n",
    "    df_without_id = df.loc[df[pairing_column] != random_id]\n",
    "    negative = df[pairing_column].sample(1, replace=True).to_list()\n",
    "    \n",
    "    return [[containing_id_list[0], containing_id_list[1], 1], [containing_id_list[0], negative[0], 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_pairs = []\n",
    "\n",
    "for record in range(images_num):\n",
    "    pair = get_balanced_pair(\"identity\", \"image\")\n",
    "    balanced_pairs.append(pair[0])\n",
    "    balanced_pairs.append(pair[1])\n",
    "    \n",
    "df = pd.DataFrame(balanced_pairs, columns =['left', 'right', 'label'])\n",
    "df['left'] = images_path + '/' + \"test_\" + df['left']\n",
    "df['right'] = images_path + '/' + \"test_\" + df['right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label\n",
       "count  10000.000000\n",
       "mean       0.500000\n",
       "std        0.500025\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.500000\n",
       "75%        1.000000\n",
       "max        1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading pairs into TF Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = tf.data.Dataset.from_tensor_slices((df['left'].values, df['right'].values, df['label'].values))\n",
    "\n",
    "dataset_features = tf.data.Dataset.from_tensor_slices((df['left'].values, df['right'].values))\n",
    "\n",
    "train_label_dataset = tf.data.Dataset.from_tensor_slices(df['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(left, right):\n",
    "        \n",
    "    return convert_to_img(left), convert_to_img(right)\n",
    "\n",
    "\n",
    "def convert_to_img(img_path):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    #img = tf.expand_dims(img, axis=0)\n",
    "    img = tf.reshape(img,(224,224,3))\n",
    "    return img\n",
    "\n",
    "def label_preprocessing(label):\n",
    "    return tf.cast(label, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_features = dataset_features.map(preprocessing)\n",
    "train_label_dataset = train_label_dataset.map(label_preprocessing)\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.zip((dataset_features, train_label_dataset))\n",
    "\n",
    "dataset = dataset.batch(batch_size, num_parallel_calls=AUTOTUNE)\n",
    "dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset element_spec=((TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None)), TensorSpec(shape=(None,), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shuffle(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.take(round(images_num * 0.8))\n",
    "val_dataset = dataset.skip(round(images_num * 0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_input = layers.Input(shape=(224, 224, 3), name='left_input')\n",
    "right_input = layers.Input(shape=(224, 224, 3), name='right_input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer False\n",
      "1 Conv2D False\n",
      "2 Conv2D False\n",
      "3 MaxPooling2D False\n",
      "4 Conv2D False\n",
      "5 Conv2D False\n",
      "6 MaxPooling2D False\n",
      "7 Conv2D False\n",
      "8 Conv2D False\n",
      "9 Conv2D False\n",
      "10 MaxPooling2D False\n",
      "11 Conv2D False\n",
      "12 Conv2D False\n",
      "13 Conv2D False\n",
      "14 MaxPooling2D False\n",
      "15 Conv2D False\n",
      "16 Conv2D False\n",
      "17 Conv2D False\n",
      "18 MaxPooling2D False\n",
      "19 GlobalAveragePooling2D True\n"
     ]
    }
   ],
   "source": [
    "vgg=vgg16.VGG16(\n",
    "    include_top=False,\n",
    "    input_shape=image_shape,\n",
    "    pooling='avg',\n",
    "    weights='imagenet',\n",
    "    classes=2)\n",
    "\n",
    "for layer in vgg.layers[0:-1]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for (i,layer) in enumerate(vgg.layers):\n",
    "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)\n",
    "    \n",
    "left_vgg16 = vgg(left_input)\n",
    "right_vgg16 = vgg(right_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging resnet branches layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = tf.reduce_sum(tf.square(subtract(x, y)), axis=1, keepdims=True)\n",
    "    return tf.sqrt(tf.maximum(sum_square, K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = layers.subtract([left_vgg16, right_vgg16])\n",
    "#merged = layers.Lambda(euclidean_distance, name=\"merge\")([left_resnet, right_resnet])\n",
    "\n",
    "flatten = layers.Flatten()(merged)\n",
    "\n",
    "merged_dense_1 = layers.Dense(256, activation='relu')(flatten)\n",
    "merged_dense_2 = layers.Dense(32, activation='relu')(merged_dense_1)\n",
    "\n",
    "merged_output = layers.Dense(1, activation='sigmoid')(merged_dense_2)\n",
    "\n",
    "model = Model(inputs = [left_input, right_input], outputs = merged_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# margin is a parametr settable by developer\n",
    "def contrastive_loss_with_margin(margin):\n",
    "    def contrastive_loss(y_true, y_pred):\n",
    "        '''Contrastive loss from Hadsell-et-al.'06\n",
    "        http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "        '''\n",
    "        square_pred = tf.square(y_pred)\n",
    "        margin_square = tf.square(tf.maximum(margin - y_pred, 0))\n",
    "        return (y_true * square_pred + (1 - y_true) * margin_square)    \n",
    "    return contrastive_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=lr), loss=contrastive_loss_with_margin(margin=1.0), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " left_input (InputLayer)        [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " right_input (InputLayer)       [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " vgg16 (Functional)             (None, 512)          14714688    ['left_input[0][0]',             \n",
      "                                                                  'right_input[0][0]']            \n",
      "                                                                                                  \n",
      " subtract (Subtract)            (None, 512)          0           ['vgg16[0][0]',                  \n",
      "                                                                  'vgg16[1][0]']                  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 512)          0           ['subtract[0][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          131328      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 32)           8224        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            33          ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,854,273\n",
      "Trainable params: 139,585\n",
      "Non-trainable params: 14,714,688\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#plot_model(resnet, show_shapes=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_fit \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mfit(train_dataset, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39mval_dataset)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model_fit = model.fit(train_dataset, epochs=5, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combo_model_fitted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [308]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mcombo_model_fitted\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(combo_model_fitted\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'combo_model_fitted' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(combo_model_fitted.history['accuracy'])\n",
    "plt.plot(combo_model_fitted.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.axis(ymin=0.5,ymax=1)\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combo_model_fitted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [307]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mcombo_model_fitted\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(combo_model_fitted\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'combo_model_fitted' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(combo_model_fitted.history['loss'])\n",
    "plt.plot(combo_model_fitted.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.axis(ymin=0,ymax=0.5)\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_image_feature_vectors = model.predict(custom_img_left)\n",
    "left_image_feature_vectors = model.predict(custom_img_right)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

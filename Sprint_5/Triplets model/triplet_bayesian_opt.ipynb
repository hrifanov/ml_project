{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import resnet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeba_path = Path('../../../Dataset/img_celeba_cropped/')\n",
    "celeba_identity_path = Path('../../Dataset/celeb_identity_processed.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_identity = pd.read_csv(\n",
    "    celeba_identity_path, \n",
    "    sep = \",\", \n",
    "    names=[\"image\", \"identity\"], \n",
    "    header=0, \n",
    "    dtype=str\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets_count=2000\n",
    "train_size=0.7\n",
    "network_input_shape=(224, 224, 3)\n",
    "\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triplet DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_n_triplets(df_identity, n):\n",
    "    triplets = []\n",
    "    \n",
    "    for triplet in range(n):\n",
    "        anchor_id = df_identity['identity'].sample(1, replace=True).to_string(index=False)\n",
    "        \n",
    "        keepGoing = True\n",
    "        while(keepGoing):\n",
    "            anchor, positive = df_identity.loc[df_identity['identity'] == anchor_id]['image'].sample(2, replace=True)\n",
    "            keepGoing = (anchor == positive)\n",
    "            \n",
    "        negative = df_identity.loc[df_identity['identity'] != anchor_id]['image'].sample(1, replace=True).to_string(index=False)\n",
    "        \n",
    "        anchor = str(celeba_path) + '/' + anchor\n",
    "        positive = str(celeba_path) + '/' + positive\n",
    "        negative = str(celeba_path) + '/' + negative\n",
    "        \n",
    "        triplets.append([anchor, positive, negative])\n",
    "        \n",
    "    return pd.DataFrame(triplets, columns=['anchor', 'positive', 'negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets = create_n_triplets(df_identity, triplets_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(anchor, positive, negative):\n",
    "    return (\n",
    "        convert_to_img(anchor), \n",
    "        convert_to_img(positive), \n",
    "        convert_to_img(negative)\n",
    "    )\n",
    "\n",
    "\n",
    "def convert_to_img(img_path):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    img = resnet50.preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tf.data.Dataset.from_tensor_slices((\n",
    "    triplets['anchor'].values, \n",
    "    triplets['positive'].values, \n",
    "    triplets['negative'].values\n",
    "))\n",
    "\n",
    "features = features.map(preprocessing)\n",
    "fake_labels = tf.data.Dataset.from_tensor_slices(np.zeros(triplets_count))\n",
    "dataset = tf.data.Dataset.zip((features, fake_labels))\n",
    "\n",
    "train_dataset = dataset.take(round(triplets_count * train_size))\n",
    "val_dataset = dataset.skip(round(triplets_count * train_size))\n",
    "\n",
    "train_dataset = train_dataset \\\n",
    "        .batch(batch_size, num_parallel_calls=tf.data.AUTOTUNE) \\\n",
    "        .prefetch(buffer_size=tf.data.AUTOTUNE) \\\n",
    "        .cache()\n",
    "\n",
    "val_dataset = val_dataset \\\n",
    "        .batch(batch_size, num_parallel_calls=tf.data.AUTOTUNE) \\\n",
    "        .prefetch(buffer_size=tf.data.AUTOTUNE) \\\n",
    "        .cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_embedding(trainable_layers, n_hidden, n_neurons, dropout_rate):\n",
    "    input = layers.Input(shape=network_input_shape)\n",
    "    \n",
    "    base_cnn=resnet50.ResNet50(\n",
    "        input_tensor=input,\n",
    "        input_shape=network_input_shape,\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "\n",
    "    for layer in base_cnn.layers[0:-trainable_layers]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    model = layers.Flatten()(base_cnn.output)\n",
    "    \n",
    "    for _ in range(n_hidden):\n",
    "        model = tf.keras.layers.Dropout(dropout_rate)(model)\n",
    "        model = tf.keras.layers.Dense(n_neurons, activation='relu')(model)\n",
    "    \n",
    "    model = layers.Dense(256)(model)\n",
    "\n",
    "    return Model(input, outputs=model, name='resnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(layers.Layer):\n",
    "\n",
    "    def __init__(self, margin, **kwargs):\n",
    "        self.margin = margin\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def euclidean_distance(self, x, y):\n",
    "        sum_square = tf.reduce_sum(tf.square(x - y), axis=1, keepdims=True)\n",
    "        return tf.sqrt(tf.maximum(sum_square, K.epsilon()))\n",
    "    \n",
    "\n",
    "    def call(self, anchor, positive, negative):\n",
    "        positive_distance = self.euclidean_distance(anchor, positive)\n",
    "        negative_distance = self.euclidean_distance(anchor, negative)\n",
    "        \n",
    "        loss = positive_distance - negative_distance\n",
    "        \n",
    "        return tf.maximum(loss + self.margin, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    trainable_layers =  hp.Int('trainable_layers', min_value=1, max_value=3, step=1, default=1)\n",
    "    n_hidden = hp.Int('n_hidden', min_value=0, max_value=5, default=1)\n",
    "    n_neurons = hp.Int('n_neurons', min_value=32, max_value=256, step=32)\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value=0, max_value=0.8, step=0.1)\n",
    "    learning_rate = hp.Float('learning_rate', min_value=1e-6, max_value=1e-2, sampling='log')\n",
    "    \n",
    "    anchor_input = layers.Input(shape=network_input_shape, name='anchor_input')\n",
    "    positive_input = layers.Input(shape=network_input_shape, name='right_input')\n",
    "    negative_input = layers.Input(shape=network_input_shape, name='negative_input')\n",
    "    \n",
    "    embedding = resnet_embedding(trainable_layers, n_hidden, n_neurons, dropout_rate)\n",
    "    \n",
    "    distances = TripletLoss(margin=1)(\n",
    "        embedding(anchor_input), \n",
    "        embedding(positive_input), \n",
    "        embedding(negative_input)\n",
    "    )\n",
    "    \n",
    "    model = Model(\n",
    "        inputs=[anchor_input, positive_input, negative_input], \n",
    "        outputs=distances,\n",
    "        name='resnet50',\n",
    "    )\n",
    "    \n",
    "    model.compile(loss=identity_loss, \n",
    "                  optimizer=Adam(learning_rate=learning_rate))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_opt_tuner = kt.BayesianOptimization(\n",
    "    build_model, \n",
    "    objective=\"val_loss\", \n",
    "    seed=42,\n",
    "    max_trials=50, \n",
    "    alpha=1e-3, #to learn (1e-4 default)\n",
    "    beta=2.6,  #to learn\n",
    "    overwrite=True, \n",
    "    directory=\"celeba_tuning\", \n",
    "    project_name=\"bayesian_opt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=4,\n",
    "    restore_best_weights=False,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "lr_scheduler_reduce = keras.callbacks.ReduceLROnPlateau(\n",
    "    factor=0.1, \n",
    "    patience=3\n",
    ")\n",
    "\n",
    "tensorboard = TensorBoard(os.path.join(bayesian_opt_tuner.project_dir, 'tensorboard'))\n",
    "\n",
    "callbacks_list = [\n",
    "    early_stopping,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 06m 50s]\n",
      "val_loss: 0.8788732290267944\n",
      "\n",
      "Best val_loss So Far: 0.8788732290267944\n",
      "Total elapsed time: 05h 20m 42s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "bayesian_opt_tuner.search(\n",
    "    train_dataset, \n",
    "    epochs=10,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_three_models = bayesian_opt_tuner.get_best_models(num_models=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtop_three_models\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "top_three_models[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x2d849b9d0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_three_models[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x2cf1106a0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_three_models[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_env)",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
